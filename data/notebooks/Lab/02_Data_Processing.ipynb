{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "## Purpose\n",
    "State the purpose of the notebook.\n",
    "## Methodology\n",
    "Quickly describle assumptions and processing steps.\n",
    "## WIP - improvements\n",
    "Use this section only if the notebook is not final.\n",
    "\n",
    "Notable TODOs:\n",
    "\n",
    "- Todo 1;\n",
    "- Todo 2;\n",
    "\n",
    "## Results\n",
    "Describe and comment the most important results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Library import\n",
    "We import all the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import rasterio\n",
    "import regionmask\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**set_lat_lon_attrs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lat_lon_attrs(ds):\n",
    "    \"\"\" Set CF latitude and longitude attributes\"\"\"\n",
    "    ds[\"lon\"] = ds.lon.assign_attrs({\n",
    "      'axis' : 'X',\n",
    "       'long_name' : 'longitude',\n",
    "        'standard_name' : 'longitude',\n",
    "         'stored_direction' : 'increasing',\n",
    "          'type' : 'double',\n",
    "           'units' : 'degrees_east',\n",
    "            'valid_max' : 360.0,\n",
    "             'valid_min' : -180.0\n",
    "             })\n",
    "    ds[\"lat\"] = ds.lat.assign_attrs({\n",
    "      'axis' : 'Y',\n",
    "       'long_name' : 'latitude',\n",
    "        'standard_name' : 'latitude',\n",
    "         'stored_direction' : 'increasing',\n",
    "          'type' : 'double',\n",
    "           'units' : 'degrees_north',\n",
    "            'valid_max' : 90.0,\n",
    "             'valid_min' : -90.0\n",
    "             })\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create_ds_mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ds_mask(df, ds, name, lon_name='lon', lat_name='lat'):\n",
    "    \"\"\"Create masks of geographical regions\"\"\"\n",
    "    # Create index column\n",
    "    if 'index' not in df:\n",
    "        df = df.reset_index(drop=True).reset_index()\n",
    "\n",
    "    # Extract indexes and geoms that are large enough!\n",
    "    id_ints = df['index'].values\n",
    "    geoms = df['geometry'].values\n",
    "    \n",
    "    print(f'Number of indexes: {len(id_ints)}')\n",
    "    print(f'Number of geoms: {len(geoms)}')\n",
    "\n",
    "\n",
    "    # create mask object\n",
    "    da_mask = regionmask.Regions(\n",
    "      name = name,\n",
    "      numbers = id_ints,\n",
    "      outlines = geoms)\\\n",
    "      .mask(ds, lon_name=lon_name, lat_name=lat_name)\\\n",
    "      .rename(name)\n",
    "\n",
    "    # get the ints actually written to mask\n",
    "    id_ints_mask = da_mask.to_dataframe().dropna()[name].unique()\n",
    "    id_ints_mask = np.sort(id_ints_mask).astype('int')\n",
    "    \n",
    "    print(f'Number of ints in mask: {len(id_ints_mask)}')\n",
    "    \n",
    "    # get the ints not written to mask\n",
    "    id_ints_not_in_mask = df[~df['index'].isin(id_ints_mask)]['index'].values\n",
    "    \n",
    "    if len(id_ints_not_in_mask) > 0: \n",
    "        print(f'Ints not in mask: {id_ints_not_in_mask}')\n",
    "    \n",
    "    # update da attributes\n",
    "    da_mask.attrs['id_ints'] = id_ints_mask\n",
    "    da_mask = set_lat_lon_attrs(da_mask)\n",
    "    \n",
    "    return da_mask, id_ints_not_in_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**find_nearest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    \"\"\"Find nearest value in numpy array\"\"\"\n",
    "    array = np.asarray(array)\n",
    "    \n",
    "    # Get the mean step values\n",
    "    step = np.abs(np.diff(array)).max()\n",
    "    \n",
    "    # Find the nearest values\n",
    "    diff = np.abs(array - value)\n",
    "    idx = np.argwhere((diff >= np.amin(diff) - step) & (diff <= np.amin(diff) + step))\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_xy_from_latlon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_from_latlon(ds, lat, lon):\n",
    "    \"\"\"Return the x/y values for a given longitude/latitude values\"\"\"\n",
    "    # Read all lon/lat values\n",
    "    lons = ds.lon.data\n",
    "    lats = ds.lat.data\n",
    "    \n",
    "    # Find the positions of the nearest longitude/latitude values\n",
    "    idx_lon = find_nearest(lons, lon)\n",
    "    idx_lat = find_nearest(lats, lat)\n",
    "    \n",
    "    # Check the identical rows in both arrays\n",
    "    res = (idx_lon[:, None] == idx_lat).all(-1).any(-1)\n",
    "    yx_positions = idx_lon[res]\n",
    "    \n",
    "    \n",
    "    if yx_positions.shape[0] == 0:\n",
    "        raise Exception(\"Sorry, lat/lon values outside data domain\")   \n",
    "    if yx_positions.shape[0] > 1:\n",
    "        # If more than one identical rows take the row nearest to the mean value\n",
    "        yx_positions = np.mean(yx_positions,axis=0).astype(int).reshape(1,2)\n",
    "\n",
    "    # Get the x/y values\n",
    "    x_position = yx_positions[0][1]\n",
    "    y_position = yx_positions[0][0]\n",
    "    x = ds.rlon.data[yx_positions[0][1]]\n",
    "    y = ds.rlat.data[yx_positions[0][0]]\n",
    "\n",
    "    return x_position, y_position, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "\n",
    "## Fenómenos climáticos extremos\n",
    "- ### Fire danger indicators\n",
    "    **[Data source](https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-tourism-fire-danger-indicators?tab=overview)**\n",
    "\n",
    "    The dataset presents projections of fire danger indicators for Europe based upon the Canadian Fire Weather Index System (FWI) under future climate conditions. The FWI is a meteorologically based index used worldwide to estimate the fire danger and is implemented in the Global ECMWF Fire Forecasting model (GEFF).\n",
    "\n",
    "    **Variables:**\n",
    "    - **Seasonal fire weather index:** \n",
    "    The mean fire weather index value over the European fire season (June-September). This is calculated as the sum of the daily fire weather index over the European fire season divided by the total number of days within this date range. The higher the index value, the more favorable the meteorological conditions to trigger a wildfire are.\n",
    "   \n",
    "- ### Bioclimatic indicators \n",
    "    **[Data source](https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-biodiversity-cmip5-regional?tab=overview)**\n",
    "\n",
    "    The dataset provides bioclimatic indicators derived from CMIP5 climate projections at 1 km x 1 km resolution for selected regions; Europe, Northern Brazil and Central Africa. This comprehensive set of bioclimatic indicators is specifically relevant for applications within the biodiversity and ecosystem services community.\n",
    "\n",
    "    **Variables:**\n",
    "    - **Precipitation in wettest quarter (BIO16):** \n",
    "    The mean of monthly mean precipitation during the wettest quarter, defined as the quarter with the highest monthly mean (of the daily mean) precipitation using a moving average of 3 consecutive months. To compute the total precipitation sum over the month, a conversion factor should be applied of 3600x24x91.3 (average number of days per quarter)*1000. This indicator corresponds to the official BIOCLIM variable BIO16.\n",
    "    - **Annual precipitation (BIO12):** \n",
    "    Annual mean of the daily mean precipitation rate (both liquid and solid phases). This indicator corresponds to the official BIOCLIM variable BIO12. To compute the total precipitation sum over the year, a conversion factor should be applied of 3600x24x365x1000 (mm year-1).\n",
    "    - **Aridity:** \n",
    "    Monthly potential evaporation divided by the monthly mean precipitation, averaged over the year.\n",
    "    - **Dry spells:** \n",
    "    Maximum number of consecutive days of the dry spells within a year.\n",
    "    - **Koeppen-Geiger class:** \n",
    "    A climate classification that divides worldwide climates into separate classes depending on temperature and precipitation thresholds.\n",
    "    \n",
    "- ### Heat waves and cold spells \n",
    "    **[Data source](https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-heat-and-cold-spells?tab=overview)**\n",
    "\n",
    "    The dataset contains the number of hot and cold spell days using different European-wide and national/regional definitions developed within the C3S European Health service. These heat wave and cold spell days are available for different future time periods and use different climate change scenarios.\n",
    "\n",
    "    **Variables:**\n",
    "    - **Heat wave days:** \n",
    "    Number of hot days in a year using specific definitions.\n",
    "    - **Cold spell days:** \n",
    "    Number of cold days in a year using specific definitions.\n",
    "    \n",
    "- ### Temperature statistics \n",
    "    **[Data source](https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-temperature-statistics?tab=overview)**\n",
    "\n",
    "    This dataset contains temperature exposure statistics for Europe (e.g. percentiles) derived from the daily 2 metre mean, minimum and maximum air temperature for the entire year, winter (DJF: December-January-February) and summer (JJA: June-July-August). These statistics were derived within the C3S European Health service and are available for different future time periods and using different climate change scenarios.\n",
    "\n",
    "    **Variables:**\n",
    "    - **Maximum temperature:** \n",
    "    Daily maximum air temperature valid for a grid cell at the height of 2m above the surface, averaged over the year or season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fire danger indicators\n",
    "\n",
    "**Read data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/raw/climate/dataset-sis-tourism-fire-danger-indicators/'\n",
    "for ns, scenario in enumerate(['rcp45', 'rcp85']):\n",
    "    if ns == 0:\n",
    "        for n, file in enumerate([i for i in os.listdir(data_dir) if scenario in i]):\n",
    "            # convert to Dataset and concatenate by time\n",
    "            if n == 0:\n",
    "                ds_fire_0 = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "                # add scenario coordinate\n",
    "                ds_fire_0 = ds_fire_0.assign_coords({\"scenario\": scenario})\n",
    "            else:\n",
    "                ds = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "                # add scenario coordinate\n",
    "                ds = ds.assign_coords({\"scenario\": scenario})\n",
    "                ds_fire_0 = xr.concat([ds_fire_0, ds], dim='time')\n",
    "    else:\n",
    "        for n, file in enumerate([i for i in os.listdir(data_dir) if scenario in i]):\n",
    "            # convert to Dataset and concatenate by time\n",
    "            if n == 0:\n",
    "                ds_fire_1 = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "                # add scenario coordinate\n",
    "                ds_fire_1 = ds_fire_1.assign_coords({\"scenario\": scenario})\n",
    "            else:\n",
    "                ds = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "                # add scenario coordinate\n",
    "                ds = ds.assign_coords({\"scenario\": scenario})\n",
    "                ds_fire_1 = xr.concat([ds_fire_1, ds], dim='time')\n",
    "                \n",
    "ds_fire = xr.concat([ds_fire_0, ds_fire_1], dim='scenario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/raw/climate/dataset-sis-tourism-fire-danger-indicators/'\n",
    "for ns, scenario in enumerate(['rcp45', 'rcp85']):\n",
    "    for n, file in enumerate([i for i in os.listdir(data_dir) if scenario in i]):\n",
    "        # convert to Dataset and concatenate by time\n",
    "        if n == 0:\n",
    "            ds_fire_sce = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "            # add scenario coordinate\n",
    "            ds_fire_sce = ds_fire_sce.assign_coords({\"scenario\": scenario})\n",
    "        else:\n",
    "            ds = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "            # add scenario coordinate\n",
    "            ds = ds.assign_coords({\"scenario\": scenario})\n",
    "            ds_fire_sce = xr.concat([ds_fire_sce, ds], dim='time')\n",
    "            \n",
    "    if ns == 0:\n",
    "        ds_fire = ds_fire_sce.copy()\n",
    "    else:\n",
    "        ds_fire = xr.concat([ds_fire, ds_fire_sce.copy()], dim='scenario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clip area**\n",
    "\n",
    "Bounding box spain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_min, lat_min, lon_max, lat_max = (-9.39288367353, 35.946850084, 4.32841, 43.7483377142)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding x/y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, y_min, x_max, y_max = (-25, -15, -10, -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fire = ds_fire.sel(rlon=slice(x_min, x_max), rlat=slice(y_min, y_max)).copy()\n",
    "ds_fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fire['fwi-mean-jjas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7.5))\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "\n",
    "ds_fire['fwi-mean-jjas'].isel(time=-1).sel(scenario='rcp85').plot.pcolormesh(ax=ax, cmap='magma', transform=ccrs.PlateCarree(), x='lon', y='lat', add_colorbar=True)\n",
    "ax.coastlines()\n",
    "ax.set_ylim([lat_min-1,lat_max+1]);\n",
    "ax.set_xlim([lon_min-1,lon_max+1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bioclimatic indicators\n",
    "\n",
    "Customized bioclimatic indicators were calculated on raw daily and monthly climate data timeseries per year. \n",
    "Monthly, annual and 20-year window statistics (for 1961-1980, 1981-2000, 2021-2040, 2041-2060, 2061-2080, 2081-2100) were calculated. Also median and spread (inter-quartile range) were calculated for the CMIP multi-model ensemble\n",
    "for each RCP scenario.\n",
    "\n",
    "    `1979-01-01T00:00:00.000000000` -> 1970-1989 \n",
    "    `1989-01-01T00:00:00.000000000` -> 1980-1999\n",
    "    `2009-01-01T00:00:00.000000000` -> 2001-2020 \n",
    "    `2030-01-01T00:00:00.000000000` -> 2021-2040\n",
    "    `2050-01-01T00:00:00.000000000` -> 2041-2060 \n",
    "    `2070-01-01T00:00:00.000000000` -> 2061-2080\n",
    "    `2090-01-01T00:00:00.000000000` -> 2081-2100\n",
    "    \n",
    "**Read data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/raw/climate/dataset-sis-biodiversity-cmip5-regional/'\n",
    "scenario = 'rcp45'\n",
    "[i for i in os.listdir(data_dir) if scenario in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/raw/climate/dataset-sis-biodiversity-cmip5-regional/'\n",
    "for ns, scenario in enumerate(['rcp45', 'rcp85']):\n",
    "    print(scenario)\n",
    "    for n, file in enumerate([i for i in os.listdir(data_dir) if scenario in i][3:]):\n",
    "        print(file)\n",
    "        if n == 0:\n",
    "            ds_bio_sce = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "        else:\n",
    "            if 'dry-spells_maximum-length' in file:\n",
    "                # Ingest the dry spells variables as float32 and not as timedelta64\n",
    "                raw = xr.open_dataset(data_dir+file, engine=\"netcdf4\", decode_cf=False)\n",
    "                del raw['dry-spells_maximum-length'].attrs['units']\n",
    "                ds = xr.decode_cf(raw)\n",
    "            else:\n",
    "                ds = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "                \n",
    "            # Assign new data variables to a Dataset\n",
    "            ds_bio_sce = ds_bio_sce.assign({list(ds.keys())[-1]: ds[list(ds.keys())[-1]]})\n",
    "            # Add scenario coordinate\n",
    "            ds_bio_sce = ds_bio_sce.assign_coords({\"scenario\": scenario})\n",
    "            \n",
    "    if ns == 0:\n",
    "        ds_bio = ds_bio_sce.copy()\n",
    "    else:\n",
    "        ds_bio = xr.concat([ds_bio, ds_bio_sce.copy()], dim='scenario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clip area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio = ds_bio.sel(longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max)).copy()\n",
    "ds_bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio['BIO16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7.5))\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "\n",
    "ds_bio['BIO16'].isel(time=-1).sel(scenario='rcp85').plot.pcolormesh(ax=ax, cmap='magma', transform=ccrs.PlateCarree(), x='longitude', y='latitude', add_colorbar=True)\n",
    "ax.coastlines()\n",
    "ax.set_ylim([lat_min-1,lat_max+1]);\n",
    "ax.set_xlim([lon_min-1,lon_max+1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat waves and cold spells \n",
    "\n",
    "**Read data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/raw/climate/dataset-sis-heat-and-cold-spells/'\n",
    "for ns, scenario in enumerate(['rcp45', 'rcp85']):\n",
    "    for n, file in enumerate([i for i in os.listdir(data_dir) if scenario in i]):\n",
    "        ds_heat_sce = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "        # Add scenario coordinate\n",
    "        ds_heat_sce = ds_heat_sce.assign_coords({\"scenario\": scenario})\n",
    "            \n",
    "    if ns == 0:\n",
    "        ds_heat = ds_heat_sce.copy()\n",
    "    else:\n",
    "        ds_heat = xr.concat([ds_heat, ds_heat_sce.copy()], dim='scenario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_heat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clip area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_heat = ds_heat.sel(lon=slice(lon_min, lon_max), lat=slice(lat_min, lat_max)).copy()\n",
    "ds_heat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7.5))\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "\n",
    "ds_heat['HWD_EU_climate'].isel(time=-1).sel(scenario='rcp85').plot.pcolormesh(ax=ax, cmap='magma', transform=ccrs.PlateCarree(), x='lon', y='lat', add_colorbar=True)\n",
    "ax.coastlines()\n",
    "ax.set_ylim([lat_min-1,lat_max+1]);\n",
    "ax.set_xlim([lon_min-1,lon_max+1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature statistics \n",
    "\n",
    "**Read data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../datasets/raw/climate/dataset-sis-temperature-statistics/'\n",
    "for ns, scenario in enumerate(['rcp45', 'rcp85']):\n",
    "    for n, file in enumerate([i for i in os.listdir(data_dir) if scenario in i]):\n",
    "        \n",
    "        if n == 0:\n",
    "            ds_temp_sce = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "            \n",
    "        else:\n",
    "            ds = xr.open_dataset(data_dir+file, engine=\"netcdf4\")\n",
    "            # Assign new data variables to a Dataset\n",
    "            ds_temp_sce = ds_temp_sce.assign({list(ds.keys())[-1]: ds[list(ds.keys())[-1]]})\n",
    "            \n",
    "        # Add scenario coordinate\n",
    "        ds_temp_sce = ds_temp_sce.assign_coords({\"scenario\": scenario})\n",
    "            \n",
    "    if ns == 0:\n",
    "        ds_temp = ds_temp_sce.copy()\n",
    "    else:\n",
    "        ds_temp = xr.concat([ds_temp, ds_temp_sce.copy()], dim='scenario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clip area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_temp = ds_temp.sel(lon=slice(lon_min, lon_max), lat=slice(lat_min, lat_max)).copy()\n",
    "ds_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7.5))\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "\n",
    "ds_temp['mean_Tmax_Summer'].isel(time=-1).sel(scenario='rcp85').plot.pcolormesh(ax=ax, cmap='magma', transform=ccrs.PlateCarree(), x='lon', y='lat', add_colorbar=True)\n",
    "ax.coastlines()\n",
    "ax.set_ylim([lat_min-1,lat_max+1]);\n",
    "ax.set_xlim([lon_min-1,lon_max+1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../datasets/raw/climate/dataset-sis-biodiversity-cmip5-regional/'\n",
    "file = 'aridity_wettest-quarter_noresm1-m_rcp45_r1i1p1_1960-2099-mean_v1.0.nc'\n",
    "\n",
    "ds_bio_sce = xr.open_dataset(data_dir+file, engine=\"netcdf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio_sce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio_sce.sel(time=slice('2009-01-01T00:00:00.000000000', '2090-01-01T00:00:00.000000000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_temp.sel(time=slice('2000-06-01T00:00:00.000000000', '2085-06-01T00:00:00.000000000')).resample(time=\"20Y\", loffset=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_temp.resample(time=\"20Y\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20-year window\n",
    "statistics (for 1961-1980, 1981-2000, 2021-2040, 2041-2060, 2061-2080, 2081-2100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
